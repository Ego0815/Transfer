ğŸ” Checkliste: Langsame App-zu-App Kommunikation in OpenShift
1ï¸âƒ£ DNS-AuflÃ¶sung prÃ¼fen

Langsame DNS-Queries sind ein hÃ¤ufiger Grund.

ğŸ‘‰ In einen Pod springen:

oc exec -it <pod-name> -- /bin/sh


ğŸ‘‰ DNS-AuflÃ¶sung messen:

time dig backend
time dig backend.my-namespace.svc.cluster.local


â¡ï¸ Erwartung: Antwort < 10 ms.
Wenn langsamer â†’ CoreDNS oder ClusterDNS checken.

2ï¸âƒ£ Direkte Netzwerk-Performance messen
a) Mit ping
oc exec -it <pod-1> -- ping -c 4 <pod-2-ip>


â¡ï¸ Wenn ping schnell, aber App langsam â†’ Problem in App oder Proxy-Ebene.

b) Mit iperf3

In einem Pod als Server starten:

iperf3 -s


In anderem Pod als Client testen:

iperf3 -c <server-pod-ip>


â¡ï¸ Liefert Throughput und Latenz.

3ï¸âƒ£ Service-Layer prÃ¼fen (ClusterIP, kube-proxy)
curl -w "@curl-format.txt" -o /dev/null -s http://backend:8080


(curl-format.txt vorher mit Timing-Parametern anlegen)

â¡ï¸ Vergleich: Pod-IP direkt vs. Service-DNS vs. Route.
Wenn Ã¼ber Service deutlich langsamer â†’ Problem bei kube-proxy oder SDN.

4ï¸âƒ£ Service Mesh Overhead checken

Falls OpenShift Service Mesh / Istio genutzt wird:

oc get pods -o yaml | grep -i "istio-proxy"


Wenn vorhanden â†’ Traffic geht durch Envoy-Sidecars.

ğŸ‘‰ Vergleichstest: einmal mit Mesh (normaler Aufruf) vs. ohne Mesh (direkte Pod-IP).
â¡ï¸ Unterschied > 5â€“10 ms â†’ Mesh-Overhead.

5ï¸âƒ£ Ressourcenlage prÃ¼fen
Pods
oc adm top pods -n <namespace>


â¡ï¸ Siehst du hohe CPU/Memory-Last?

Nodes
oc adm top nodes


â¡ï¸ Ãœberlastete Nodes = langsame Netzwerkarbeit.

6ï¸âƒ£ Netzwerk-Konfiguration prÃ¼fen
MTU prÃ¼fen (hÃ¤ufiger Fehler bei Overlay-Netzen)
oc exec -it <pod> -- ip a


â¡ï¸ MTU-Werte mÃ¼ssen mit Host-Nodes Ã¼bereinstimmen.
Zu kleine MTU = Fragmentierung â†’ langsamer Traffic.

7ï¸âƒ£ Security Layer prÃ¼fen

NetworkPolicies vorhanden?

oc get networkpolicies -A


ZusÃ¤tzliche Firewalls / IDS-Systeme aktiv?

â¡ï¸ Test: Kommunikation ohne Policies â†’ schneller?

8ï¸âƒ£ Infrastruktur-Ebene

PrÃ¼fen, ob Pods auf verschiedenen Nodes laufen:

oc get pod -o wide


Test: Beide Pods auf demselben Node (Affinity) starten â†’ schneller?
â¡ï¸ Wenn ja: Cluster-Netzwerk/Overlay die Ursache.
